# ğŸ“¦ å®‰è£…æŒ‡å—

## ç³»ç»Ÿè¦æ±‚

- **Python**: 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- **FFmpeg**: å¿…éœ€ï¼Œç”¨äºéŸ³é¢‘/è§†é¢‘å¤„ç†
- **GPU** (å¯é€‰): å¦‚æœä½¿ç”¨æœ¬åœ° Whisperï¼Œå»ºè®® NVIDIA GPU (4GB+ æ˜¾å­˜)

---

## åŸºç¡€å®‰è£…

### 1. å®‰è£… FFmpeg

**macOS**:
```bash
brew install ffmpeg
```

**Ubuntu/Debian**:
```bash
sudo apt update
sudo apt install ffmpeg
```

**Windows**:
1. ä¸‹è½½ [FFmpeg](https://ffmpeg.org/download.html)
2. è§£å‹åˆ° `C:\ffmpeg`
3. æ·»åŠ  `C:\ffmpeg\bin` åˆ°ç³»ç»Ÿ PATH

éªŒè¯å®‰è£…ï¼š
```bash
ffmpeg -version
```

### 2. å®‰è£… SubGen

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/YOUR_USERNAME/subgen.git
cd subgen

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 3. é…ç½®

```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp config.example.yaml config.yaml

# ç¼–è¾‘é…ç½®ï¼Œå¡«å…¥ API Keys
nano config.yaml  # æˆ–ä½¿ç”¨ä½ å–œæ¬¢çš„ç¼–è¾‘å™¨
```

---

## å¯é€‰ï¼šæœ¬åœ° Whisper

å¦‚æœä½ æœ‰ NVIDIA GPUï¼Œå¯ä»¥åœ¨æœ¬åœ°è¿è¡Œ Whisperï¼ˆå…è´¹ä¸”æ›´å¿«ï¼‰ï¼š

### 1. å®‰è£… CUDA

ç¡®ä¿å·²å®‰è£… NVIDIA é©±åŠ¨å’Œ CUDAã€‚æ£€æŸ¥ï¼š
```bash
nvidia-smi
```

### 2. å®‰è£… PyTorch

```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 3. å®‰è£… faster-whisper

```bash
pip install faster-whisper
```

### 4. éªŒè¯

```python
from faster_whisper import WhisperModel
model = WhisperModel("base", device="cuda")
print("Whisper æœ¬åœ°è¿è¡ŒæˆåŠŸï¼")
```

---

## å¯é€‰ï¼šæœ¬åœ° LLM (Ollama)

å¦‚æœä½ æƒ³å®Œå…¨ç¦»çº¿ç¿»è¯‘ï¼š

### 1. å®‰è£… Ollama

**macOS/Linux**:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Windows**:
ä¸‹è½½ [Ollama å®‰è£…åŒ…](https://ollama.com/download)

### 2. ä¸‹è½½æ¨¡å‹

```bash
# æ¨èï¼šQwen2.5 (ä¸­æ–‡ä¼˜åŒ–)
ollama pull qwen2.5:14b

# æˆ–ï¼šLlama 3
ollama pull llama3:8b
```

### 3. å¯åŠ¨æœåŠ¡

```bash
ollama serve
```

### 4. é…ç½® SubGen

åœ¨ `config.yaml` ä¸­ï¼š
```yaml
translation:
  provider: "ollama"
  ollama_host: "http://localhost:11434"
  ollama_model: "qwen2.5:14b"
```

---

## å¸¸è§é—®é¢˜

### FFmpeg æ‰¾ä¸åˆ°

**é”™è¯¯**: `FileNotFoundError: ffmpeg not found`

**è§£å†³**:
1. ç¡®è®¤ FFmpeg å·²å®‰è£…ï¼š`ffmpeg -version`
2. ç¡®è®¤ FFmpeg åœ¨ PATH ä¸­
3. æˆ–åœ¨é…ç½®ä¸­æŒ‡å®šå®Œæ•´è·¯å¾„

### CUDA å†…å­˜ä¸è¶³

**é”™è¯¯**: `CUDA out of memory`

**è§£å†³**:
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼š`local_model: "medium"` æˆ– `"small"`
2. å…³é—­å…¶ä»–å ç”¨ GPU çš„ç¨‹åº
3. ä½¿ç”¨äº‘ç«¯ API ä»£æ›¿æœ¬åœ°

### API è¯·æ±‚å¤±è´¥

**é”™è¯¯**: `APIError: 401 Unauthorized`

**è§£å†³**:
1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆï¼ˆæ˜¯å¦è¿‡æœŸã€æ˜¯å¦æœ‰é¢åº¦ï¼‰
3. æ£€æŸ¥ç½‘ç»œè¿æ¥

---

## ä¸‹ä¸€æ­¥

å®‰è£…å®Œæˆåï¼Œè¯·æŸ¥çœ‹ï¼š
- [é…ç½®è¯´æ˜](configuration.md) - è¯¦ç»†é…ç½®é€‰é¡¹
- [API æä¾›å•†è®¾ç½®](providers.md) - å¦‚ä½•è·å–å„æœåŠ¡çš„ API Key
