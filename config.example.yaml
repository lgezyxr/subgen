# SubGen Configuration File
# Copy to config.yaml and fill in your API Keys

# ============================================
# Speech Recognition (Whisper)
# ============================================
whisper:
  # Provider: local | mlx | openai | groq
  # - local: faster-whisper, needs NVIDIA GPU
  # - mlx: Apple Silicon optimized (M1/M2/M3 Mac)
  # - groq: Free tier, very fast
  # - openai: $0.006/min
  provider: "groq"

  # Model (for local/mlx): tiny | base | small | medium | large-v3
  local_model: "large-v3"

  # Device (for local only): cuda | cpu
  device: "cuda"

  # API Keys (fill in as needed)
  openai_key: ""      # OpenAI API Key (sk-...)
  groq_key: ""        # Groq API Key (gsk_...)

# ============================================
# Translation (LLM)
# ============================================
translation:
  # Provider: openai | claude | deepseek | ollama | copilot
  # - copilot: Use GitHub Copilot subscription (OAuth login)
  # - openai: gpt-4o-mini recommended
  # - deepseek: Good for Chinese
  # - ollama: Local LLM
  provider: "copilot"

  # Model selection (depends on provider)
  # 
  # For Copilot (GitHub Copilot subscription):
  #   Claude:
  model: "claude-sonnet-4"     # Default, balanced
  #   model: "claude-sonnet-4.5"  # Newer Sonnet
  #   model: "claude-opus-4.5"    # Best quality
  #   model: "claude-haiku-4.5"   # Fast & cheap
  #   GPT:
  #   model: "gpt-4o"             # GPT-4o
  #   model: "gpt-5"              # GPT-5
  #   model: "gpt-5.1"            # GPT-5.1
  #   model: "gpt-5.2"            # GPT-5.2 (best GPT)
  #   Gemini:
  #   model: "gemini-2.5-pro"     # Gemini 2.5 Pro
  #   model: "gemini-3-flash"     # Fast
  #   model: "gemini-3-pro"       # Quality
  #   Reasoning:
  #   model: "o1-mini"            # Fast reasoning
  #   model: "o1-preview"         # Better reasoning
  #   model: "o3-mini"            # Newest reasoning
  #
  # For OpenAI API:
  #   model: "gpt-4o-mini"        # Best value
  #   model: "gpt-4o"             # Best quality
  #
  # For DeepSeek:
  #   model: "deepseek-chat"      # Chinese optimized

  # API configuration
  api_key: ""         # API Key (not needed for copilot)
  base_url: ""        # Custom API URL (optional)

  # Ollama configuration (local LLM)
  ollama_host: "http://localhost:11434"
  ollama_model: "qwen2.5:14b"

# ============================================
# Output Settings
# ============================================
output:
  # Subtitle format: srt | ass | vtt
  format: "srt"

  # Target language for translation
  target_language: "zh"  # zh | ja | ko | en | ...

  # Bilingual subtitles (original + translated)
  bilingual: false

  # Max characters per line
  max_chars_per_line: 42

  # Burn subtitles into video
  embed_in_video: false

# ============================================
# Advanced Settings
# ============================================
advanced:
  # Translation batch size
  translation_batch_size: 20

  # Context lines for translation
  translation_context_size: 5

  # Temp directory
  temp_dir: "./temp"

  # Keep intermediate files (for debugging)
  keep_temp_files: false

  # Log level: DEBUG | INFO | WARNING | ERROR
  log_level: "INFO"

  # Music/noise filtering (uses Whisper's no_speech_prob)
  filter_music: false              # Enable automatic music/noise detection
  no_speech_threshold: 0.6        # Skip segments with no_speech_prob above this
  max_no_speech_duration: 30.0    # For long segments, use lower threshold (0.5)

  # Long segment handling
  split_long_segments: true       # Split segments longer than max_segment_duration
  max_segment_duration: 15.0      # Maximum segment duration in seconds

  # Segment validation (detect music/noise by speech density)
  validate_segments: false         # Enable validation
  min_words_per_sec: 0.3          # Minimum words/second (below = likely music)
  min_duration_for_density_check: 20.0  # Only check segments longer than this

  # Proofreading settings
  proofread_batch_size: null        # Auto-set based on model (override: 15-60)
  proofread_context_chars: null   # Auto-set based on model (override: 3000-20000)

# ============================================
# Subtitle Styles (ASS format)
# ============================================
styles:
  # Preset: default | netflix | fansub | minimal
  preset: "default"

  # Override primary subtitle (translation) style
  primary:
    font: "Arial"
    size: 60
    color: "#FFFFFF"
    bold: false
    outline: 3
    outline_color: "#000000"

  # Override secondary subtitle (original) style
  secondary:
    font: "Arial"
    size: 45
    color: "#AAAAAA"
    bold: false
    outline: 2
