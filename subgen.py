#!/usr/bin/env python3
"""
SubGen - AI å­—å¹•ç”Ÿæˆå·¥å…·
ä¸»ç¨‹åºå…¥å£
"""

import click
from pathlib import Path
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn

from src.config import load_config
from src.audio import extract_audio
from src.transcribe import transcribe_audio
from src.translate import translate_segments
from src.subtitle import generate_subtitle, embed_subtitle

console = Console()


@click.command()
@click.argument('input_path', type=click.Path(exists=True))
@click.option('--output', '-o', type=click.Path(), help='è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„')
@click.option('--target-lang', '-t', default='zh', help='ç›®æ ‡ç¿»è¯‘è¯­è¨€ (é»˜è®¤: zh)')
@click.option('--bilingual', '-b', is_flag=True, help='ç”ŸæˆåŒè¯­å­—å¹•')
@click.option('--whisper-provider', type=click.Choice(['local', 'openai', 'groq']), help='è¦†ç›–é…ç½®çš„ Whisper æä¾›å•†')
@click.option('--llm-provider', type=click.Choice(['openai', 'claude', 'deepseek', 'ollama']), help='è¦†ç›–é…ç½®çš„ LLM æä¾›å•†')
@click.option('--embed', is_flag=True, help='å°†å­—å¹•çƒ§å½•è¿›è§†é¢‘')
@click.option('--config', '-c', type=click.Path(exists=True), default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
@click.option('--verbose', '-v', is_flag=True, help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
def main(input_path, output, target_lang, bilingual, whisper_provider, llm_provider, embed, config, verbose):
    """
    SubGen - AI å­—å¹•ç”Ÿæˆå·¥å…·
    
    ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼Œä½¿ç”¨ AI è¿›è¡Œè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ï¼Œç”Ÿæˆå­—å¹•æ–‡ä»¶ã€‚
    
    ç¤ºä¾‹:
    
        python subgen.py movie.mp4
        
        python subgen.py movie.mp4 --target-lang zh --bilingual
        
        python subgen.py movie.mp4 -o output.srt --whisper-provider local
    """
    
    input_path = Path(input_path)
    
    # åŠ è½½é…ç½®
    try:
        cfg = load_config(config)
    except FileNotFoundError:
        console.print("[red]é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚è¯·å¤åˆ¶ config.example.yaml ä¸º config.yaml å¹¶å¡«å…¥ API Keys[/red]")
        raise SystemExit(1)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if whisper_provider:
        cfg['whisper']['provider'] = whisper_provider
    if llm_provider:
        cfg['translation']['provider'] = llm_provider
    if target_lang:
        cfg['output']['target_language'] = target_lang
    if bilingual:
        cfg['output']['bilingual'] = True
    if embed:
        cfg['output']['embed_in_video'] = True
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output:
        output_path = Path(output)
    else:
        suffix = '.srt' if cfg['output']['format'] == 'srt' else f".{cfg['output']['format']}"
        output_path = input_path.with_suffix(suffix)
    
    console.print(f"\n[bold blue]ğŸ¬ SubGen - AI å­—å¹•ç”Ÿæˆå·¥å…·[/bold blue]\n")
    console.print(f"è¾“å…¥: [cyan]{input_path}[/cyan]")
    console.print(f"è¾“å‡º: [cyan]{output_path}[/cyan]")
    console.print(f"Whisper: [yellow]{cfg['whisper']['provider']}[/yellow]")
    console.print(f"ç¿»è¯‘: [yellow]{cfg['translation']['provider']}[/yellow] ({cfg['translation']['model']})")
    console.print(f"ç›®æ ‡è¯­è¨€: [yellow]{cfg['output']['target_language']}[/yellow]")
    console.print(f"åŒè¯­å­—å¹•: [yellow]{'æ˜¯' if cfg['output']['bilingual'] else 'å¦'}[/yellow]")
    console.print()
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TimeElapsedColumn(),
        console=console,
    ) as progress:
        
        # Step 1: æå–éŸ³é¢‘
        task1 = progress.add_task("[cyan]æå–éŸ³é¢‘...", total=None)
        audio_path = extract_audio(input_path, cfg)
        progress.update(task1, completed=True, description="[green]âœ“ éŸ³é¢‘æå–å®Œæˆ")
        
        # Step 2: è¯­éŸ³è¯†åˆ«
        task2 = progress.add_task("[cyan]è¯­éŸ³è¯†åˆ«ä¸­...", total=None)
        segments = transcribe_audio(audio_path, cfg)
        progress.update(task2, completed=True, description=f"[green]âœ“ è¯†åˆ«å®Œæˆ ({len(segments)} æ¡å­—å¹•)")
        
        # Step 3: ç¿»è¯‘
        task3 = progress.add_task("[cyan]ç¿»è¯‘ä¸­...", total=len(segments))
        translated_segments = translate_segments(
            segments, 
            cfg, 
            progress_callback=lambda n: progress.update(task3, advance=n)
        )
        progress.update(task3, completed=len(segments), description="[green]âœ“ ç¿»è¯‘å®Œæˆ")
        
        # Step 4: ç”Ÿæˆå­—å¹•
        task4 = progress.add_task("[cyan]ç”Ÿæˆå­—å¹•...", total=None)
        generate_subtitle(translated_segments, output_path, cfg)
        progress.update(task4, completed=True, description="[green]âœ“ å­—å¹•ç”Ÿæˆå®Œæˆ")
        
        # Step 5: åµŒå…¥è§†é¢‘ (å¯é€‰)
        if cfg['output']['embed_in_video']:
            task5 = progress.add_task("[cyan]åµŒå…¥å­—å¹•åˆ°è§†é¢‘...", total=None)
            video_output = input_path.with_stem(input_path.stem + '_subbed')
            embed_subtitle(input_path, output_path, video_output, cfg)
            progress.update(task5, completed=True, description="[green]âœ“ è§†é¢‘ç”Ÿæˆå®Œæˆ")
    
    console.print(f"\n[bold green]âœ… å®Œæˆï¼[/bold green]")
    console.print(f"å­—å¹•æ–‡ä»¶: [cyan]{output_path}[/cyan]")
    
    if cfg['output']['embed_in_video']:
        console.print(f"è§†é¢‘æ–‡ä»¶: [cyan]{video_output}[/cyan]")


if __name__ == '__main__':
    main()
